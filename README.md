# ğŸ¤– Resume Screener AI â€“ Intelligent CV Filtering & Analytics

An offline/local-first application to automatically screen multiple CVs based on a Job Description (JD), generate skill gap analysis, ATS score, and visual analytics.

## ğŸ§° Tech Stack

### ğŸ–¥ï¸ Frontend
- **Next.js** â€“ For modern SPA dashboard
- **Tailwind CSS** â€“ For responsive UI styling
- **ShadCN UI / Recharts** â€“ Clean UI + analytics chart components
- **Zustand** â€“ Simple global state management
- **React Query** â€“ For data fetching
- **React Hook Form** â€“ For form management
- **Zod** â€“ For data validation

### âš™ï¸ Backend
- **Next.js API Routes** â€“ REST API for document processing
- **LangChain.js / Python** â€“ Orchestration of LLM + embedding logic (planned)
- **Python libraries** (planned):
  - `spaCy` â€“ For NLP preprocessing
  - `scikit-learn` â€“ For similarity scoring & gap detection
  - `wordcloud` â€“ To generate skill-based word cloud
  - `pdfminer.six`, `docx`, `textract` â€“ For parsing CV files

### ğŸ§  AI Models (planned)
- **LLM (via Ollama)** â€“ e.g., `Mistral`, `LLaMA3` for JD understanding & summary
- **Embeddings** â€“ `bge-m3` or `Instructor-XL` for skill matching
- **Local Sentence Transformer** â€“ For similarity scoring between JD & CV

### ğŸ“¦ Storage & Processing (planned)
- **ChromaDB** â€“ Local vector DB for semantic CV search
- **SQLite / LowDB** â€“ User data, logs, job postings
- **Local File System** â€“ For CV uploads and metadata

## ğŸ“‚ Key Features

- ğŸ“ Upload multiple CVs (PDF, DOCX, TXT)
- ğŸ“Œ Input single Job Description text
- ğŸ“ˆ Sort candidates based on:
  - Semantic similarity (LLM embeddings)
  - Keyword match
  - Skill gap (missing from CV)
  - ATS readiness score
- ğŸ“Š Word cloud of skill frequencies
- ğŸ§  Auto-summary of top candidates

## ğŸ”’ Offline-Ready
- All models run locally (no API keys needed)
- CVs and job data never leave user's device

## Getting Started

### Prerequisites

- Node.js 18+ and pnpm
- For full functionality (planned): Python 3.9+ with pip

### Installation

1. Clone the repository
```bash
git clone https://github.com/yourusername/screen-ai.git
cd screen-ai
```

2. Install dependencies
```bash
pnpm install
```

3. Create uploads directory
```bash
mkdir -p public/uploads
```

4. Run the development server
```bash
pnpm dev
```

5. Open [http://localhost:3000](http://localhost:3000) with your browser

## Future Enhancements

- Export filtered candidates to CSV
- Compare 2 CVs head-to-head
- Add resume builder/editor for rejected candidates
- Integration with local LLM models via Ollama
